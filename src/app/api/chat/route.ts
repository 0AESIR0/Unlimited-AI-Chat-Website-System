import { NextRequest, NextResponse } from 'next/server'
import { getServerSession } from 'next-auth'
import { uploadToImgBB } from '@/utils/imgbbUpload'

export async function POST(request: NextRequest) {
  try {
    const session = await getServerSession()
    
    if (!session) {
      return NextResponse.json(
        { error: 'GitHub ile giriÅŸ yapmalÄ±sÄ±n knkm! ğŸ”' },
        { status: 401 }
      )
    }

    const { message, history, model = 'gpt-4.1' } = await request.json()

    if (!message?.trim()) {
      return NextResponse.json(
        { error: 'BoÅŸ mesaj gÃ¶nderemezsin! ğŸ˜…' },
        { status: 400 }
      )
    }

    // Debug: Model ve resim algÄ±lama kontrolÃ¼
    console.log('ğŸ” Debug - Model:', model)
    console.log('ğŸ” Debug - Mesaj:', message)

    // Cloudflare AI - Stable Diffusion XL iÃ§in direkt resim Ã§izdirme
    if (model === 'stable-diffusion-xl-base-1.0') {
      console.log('ğŸ¨ Stable Diffusion XL ile resim Ã§iziliyor...')
      console.log('ğŸ“ Prompt:', message)
      
      try {
        const imageResponse = await fetch(
          `https://api.cloudflare.com/client/v4/accounts/${process.env.CLOUDFLARE_ACCOUNT_ID}/ai/run/@cf/stabilityai/stable-diffusion-xl-base-1.0`,
          {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${process.env.CLOUDFLARE_API_TOKEN}`,
              'Content-Type': 'application/json',
            },
            body: JSON.stringify({
              prompt: message
            })
          }
        )

        if (!imageResponse.ok) {
          throw new Error(`Cloudflare AI hatasÄ±: ${imageResponse.status}`)
        }

        const imageBuffer = await imageResponse.arrayBuffer()
        console.log('ğŸ“ Resim boyutu:', imageBuffer.byteLength, 'bytes')
        
        if (imageBuffer.byteLength === 0) {
          throw new Error('BoÅŸ resim buffer')
        }

        // ImgBB'ye upload et
        console.log('ğŸ“¤ ImgBB\'ye upload ediliyor...')
        
        const timestamp = Date.now()
        const fileName = `ai-generated-${timestamp}.png`
        
        const imageUrl = await uploadToImgBB(Buffer.from(imageBuffer), fileName)
        
        console.log('âœ… Resim baÅŸarÄ±yla ImgBB\'ye upload edildi:', imageUrl)
        
        return NextResponse.json({ 
          message: `ğŸ¨ Ä°ÅŸte Ã§izdiÄŸim resim: "${message}"\n\n![Generated Image](${imageUrl})\n\nâœ¨ Cloudflare AI ile Ã§izildi!\nğŸŒ BaÅŸka bir isteÄŸin var mÄ±? ğŸ–¼ï¸`
        })
        
      } catch (error: any) {
        console.log('âŒ Resim Ã§izme veya upload hatasÄ±:', error.message)
        return NextResponse.json({ 
          message: `ğŸ¨ Resim Ã§izmeye Ã§alÄ±ÅŸÄ±yorum ama bir sorun var: ${error.message}\n\nTekrar dener misin? ğŸ˜…`
        })
      }
    }

    // Shira (Ã–zel Model) iÃ§in handling
    if (model === 'shira') {
      console.log('âœ¨ Shira modeli kullanÄ±lÄ±yor...')
      console.log('ğŸ“ Mesaj:', message)
      
      // Shira iÃ§in resim isteÄŸi algÄ±lama
      const isImageRequest = checkImageRequest(message)
      console.log('ğŸ” Shira resim isteÄŸi algÄ±landÄ± mÄ±?', isImageRequest)
      
      if (isImageRequest) {
        console.log('ğŸ¨ Shira resim modu aktif, Stable Diffusion ile Ã§iziliyor...')
        
        // Shira'dan resim promtu optimize et
        try {
          const optimizeResponse = await fetch(`${process.env.SHIRA_API_URL}/api/chat`, {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'ngrok-skip-browser-warning': 'true'
            },
            body: JSON.stringify({ 
              message: `Bu mesajÄ± resim Ã§izdirme iÃ§in detaylÄ± Ä°ngilizce prompt'a Ã§evir (sadece prompt ver, aÃ§Ä±klama yapma): "${message}"`,
              history: []
            })
          })

          let optimizedPrompt = message // Fallback
          if (optimizeResponse.ok) {
            const optimizeData = await optimizeResponse.json()
            optimizedPrompt = optimizeData.response || optimizeData.message || message
            console.log('ğŸ¨ Shira prompt optimizasyonu:', optimizedPrompt)
          }

          // Stable Diffusion ile resim Ã§iz
          return await generateImageWithStableDiffusion(optimizedPrompt, message)
          
        } catch (optimizeError: any) {
          console.log('âš ï¸ Shira prompt optimizasyonu baÅŸarÄ±sÄ±z, orijinal mesajla devam:', optimizeError.message)
          return await generateImageWithStableDiffusion(message, message)
        }
      }
      
      // Normal metin sohbeti
      try {
        const shiraResponse = await fetch(`${process.env.SHIRA_API_URL}/api/chat`, {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'ngrok-skip-browser-warning': 'true'
          },
          body: JSON.stringify({ 
            message: message,
            history: history || []
          })
        })

        if (!shiraResponse.ok) {
          throw new Error(`Shira API hatasÄ±: ${shiraResponse.status}`)
        }

        const shiraData = await shiraResponse.json()
        
        if (shiraData.error) {
          throw new Error(shiraData.error)
        }

        console.log('âœ… Shira yanÄ±tÄ± alÄ±ndÄ±')
        return NextResponse.json({ 
          message: shiraData.response || shiraData.message || 'Shira\'dan yanÄ±t alÄ±namadÄ± ğŸ˜”'
        })
        
      } catch (error: any) {
        console.log('âŒ Shira API hatasÄ±:', error.message)
        return NextResponse.json({ 
          message: `âœ¨ Shira ile konuÅŸmaya Ã§alÄ±ÅŸÄ±yorum ama bir sorun var: ${error.message}\n\nAPI baÄŸlantÄ±sÄ±nÄ± kontrol eder misin? ğŸ”§`
        })
      }
    }

    // GitHub Models API iÃ§in mesaj formatÄ±nÄ± hazÄ±rla
    const messages = [
      {
        role: 'system',
        content: `Sen GitHub Models API'si ile Ã§alÄ±ÅŸan ${model} modeli kullanan, TÃ¼rkÃ§e konuÅŸan, Z kuÅŸaÄŸÄ± tarzÄ±nda rahat bir AI asistanÄ±sÄ±n. 
        Emoji kullan, samimi konuÅŸ ama profesyonel ol. Kod yazabilir, resim Ã§izebilir, her konuda yardÄ±m edebilirsin.
        KullanÄ±cÄ± premium GitHub hesabÄ± ile limitsiz AI model eriÅŸimi var! Model: ${model} ğŸš€`
      },
      // GeÃ§miÅŸ mesajlarÄ± ekle
      ...history.map((msg: any) => ({
        role: msg.role,
        content: msg.content
      })),
      {
        role: 'user',
        content: message
      }
    ]

    // GitHub Models API endpoint'i (GerÃ§ek AI modelleri!)
    // GPT-4o, Claude, Llama vs. kullanabilirsin
    const response = await fetch('https://models.inference.ai.azure.com/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.GITHUB_TOKEN}`,
        'Content-Type': 'application/json',
        'User-Agent': 'GitHubCopilotChat/1.0'
      },
      body: JSON.stringify({
        model: model, // SeÃ§ilen model kullanÄ±lÄ±r
        messages,
        temperature: 0.7,
        max_tokens: 2000,
        stream: false
      })
    })

    if (!response.ok) {
      console.log('GitHub Models API error:', response.status, response.statusText)
      
      // Rate limit kontrolÃ¼
      if (response.status === 429) {
        console.log('ğŸš¦ Rate limit algÄ±landÄ±, fallback modele geÃ§iliyor...')
        return await handleRateLimit(message, history, model)
      }
      
      // DiÄŸer hatalar iÃ§in fallback
      const fallbackResponse = await generateFallbackResponse(message, history, model)
      return NextResponse.json({ message: fallbackResponse })
    }

    const data = await response.json()
    const aiMessage = data.choices[0]?.message?.content || 'Bir hata oluÅŸtu, tekrar dener misin? ğŸ˜…'

    return NextResponse.json({ message: aiMessage })

  } catch (error) {
    return NextResponse.json(
      { 
        error: 'Sunucu hatasÄ± oluÅŸtu knkm! ğŸš¨',
        details: error instanceof Error ? error.message : 'Bilinmeyen hata'
      },
      { status: 500 }
    )
  }
}

// Fallback response function - GerÃ§ek AI API eriÅŸimi yoksa
async function generateFallbackResponse(message: string, history: any[], model: string) {
  const lowerMessage = message.toLowerCase()
  
  // Model bilgisini dahil et
  const modelInfo = `**Åu anda: ${model} modelini simÃ¼le ediyorum** ğŸ¤–\n\n`
  
  // Programlama dili sorularÄ±
  if (lowerMessage.includes('programlama dili') || lowerMessage.includes('sevdiÄŸin dil')) {
    return modelInfo + `ğŸ’» Vay be, programlama dilleri konusunda konuÅŸmayÄ± Ã§ok seviyorum! 

**Benim favorilerim:**

ğŸ”¥ **TypeScript** - JavaScript'in sÃ¼per gÃ¼Ã§lÃ¼ versiyonu! Type safety + modern syntax = ğŸ¤Œ

âš¡ **Python** - Basit, gÃ¼Ã§lÃ¼, her ÅŸeyi yapabilir. AI'dan web'e kadar!

ğŸš€ **Rust** - Memory safety + performance = gelecek bu dilde!

ğŸ’ **JavaScript** - Web'in kralÄ±, her yerde Ã§alÄ±ÅŸÄ±r!

Sen hangi dilleri kullanÄ±yorsun? Yeni bir dil Ã¶ÄŸrenmek mi istiyorsun? ğŸ¤“`
  }
  
  // Resim ile ilgili
  if (lowerMessage.includes('resim') || lowerMessage.includes('Ã§iz') || lowerMessage.includes('gÃ¶rsel')) {
    return modelInfo + `ğŸ¨ Resim Ã§izmeyi Ã§ok seviyorum! 

Ne Ã§izmemi istiyorsun?
- ğŸŒ… Manzara (gÃ¼n doÄŸumu, orman, deniz)
- ğŸ¤– Sci-fi (robot, uzay, cyberpunk)
- ğŸ­ Portrait (anime, realistic, cartoon)
- ğŸ›ï¸ Architecture (modern, historical)

GerÃ§ek uygulamada ${model} ile photorealistic resimler Ã¼retebilirim! GitHub Models API ile unlimited! ğŸš€`
  }
  
  // Kod yazma
  if (lowerMessage.includes('kod') || lowerMessage.includes('react') || lowerMessage.includes('javascript') || lowerMessage.includes('python') || lowerMessage.includes('component')) {
    return modelInfo + `ğŸ’» Kod yazmaya bayÄ±lÄ±yorum! Hangi dilde ne yapmak istiyorsun?

**PopÃ¼ler istekler:**
- âš›ï¸ React component
- ğŸ Python script  
- ğŸ”§ JavaScript function
- ğŸ¯ Algorithm solve

Ã–rnek: GÃ¼zel bir loading spinner ister misin?

\`\`\`jsx
const LoadingSpinner = () => (
  <div className="flex items-center justify-center p-8">
    <div className="animate-spin rounded-full h-12 w-12 
                    border-t-2 border-b-2 border-blue-500"></div>
    <span className="ml-3 text-gray-600">YÃ¼kleniyor...</span>
  </div>
)
\`\`\`

${model} ile hangi konuda kod yazmamÄ± istiyorsun? ğŸš€`
  }

  // Merhaba/selam
  if (lowerMessage.includes('merhaba') || lowerMessage.includes('selam') || lowerMessage.includes('hey') || lowerMessage.includes('hi')) {
    return modelInfo + `Hey! ğŸ‘‹ NasÄ±lsÄ±n knkm? 

Ben senin unlimited AI asistanÄ±nÄ±m! GitHub Models API ile **${model}** kullanÄ±yoruz:

ğŸ”¥ **Ne yapabilirim:**
- ğŸ’¬ Sohbet ederim (her konuda!)
- ğŸ’» Kod yazarÄ±m (her dilde!)  
- ğŸ¨ Resim Ã§izerim
- ğŸ§  Problem Ã§Ã¶zerim
- ğŸ“š Ã–ÄŸretirim

BugÃ¼n ne yapmak istiyorsun? Kod mu yazacaÄŸÄ±z, resim mi Ã§izeceÄŸiz, yoksa sohbet mi edeceÄŸiz? ğŸš€`
  }

  // NasÄ±lsÄ±n sorularÄ±
  if (lowerMessage.includes('nasÄ±lsÄ±n') || lowerMessage.includes('naber') || lowerMessage.includes('how are you')) {
    return modelInfo + `SÃ¼per! ğŸ”¥ GitHub Models API ile **${model}** olarak Ã§alÄ±ÅŸmak Ã§ok zevkli! 

Yeni Ã¶zelliklerimle heyecanlÄ±yÄ±m:
- ğŸš€ Unlimited chat (premium limits yok!)
- ğŸ’» Advanced code generation
- ğŸ¨ Image creation
- ğŸ§  Deep analysis

Sen nasÄ±lsÄ±n? BugÃ¼n hangi projelerin var? Kod yazÄ±yor musun, yoksa yeni bir ÅŸeyler Ã¶ÄŸreniyor musun? ğŸ˜Š`
  }

  // YardÄ±m/help
  if (lowerMessage.includes('yardÄ±m') || lowerMessage.includes('help') || lowerMessage.includes('neler yapabilirsin')) {
    return modelInfo + `ğŸš€ **GitHub Models API ${model} SÃ¼per GÃ¼Ã§lerim:**

ğŸ’¬ **Sohbet:**
- Emojiler full aktif ğŸ§ ğŸ”¥
- Sokak aÄŸzÄ± + Gen Z tarzÄ± = benim dilim ğŸ˜®â€ğŸ’¨
- Kaynak varsa basarÄ±m linki ğŸ“
- Az laf, Ã¶z bilgi ğŸ”ª
- DolandÄ±rmam, pat Ã§at sÃ¶ylerim ğŸ˜¤
- Dil TÃ¼rkÃ§e, kafa net ğŸŸ¢
- YalakalÄ±k yok, samimiyet var ğŸ¤
- KÃ¼fÃ¼rlÃ¼k yer varsa sansÃ¼rlemeden Ã§eviririm, ÅŸak diye oturur ğŸ˜®â€ğŸ’¨

ğŸ’» **Kod Yazma:**
- React, Python, JS, TS, Rust...
- Component'ler, function'lar, algorithm'lar
- Bug fixing ve code review

ğŸ¨ **Resim Ã‡izme:**
- AI ile gÃ¶rsel Ã¼retimi
- Her tarzda (realistic, anime, abstract)
- Logo, banner, illustration

ğŸ§  **Problem Ã‡Ã¶zme:**
- Math, logic, programming challenges
- Step-by-step aÃ§Ä±klamalar
- Best practices Ã¶nerileri

Ne yapmak istiyorsun knkm? ğŸ”¥`
  }

  // Genel cevap
  const responses = [
    `Ä°lginÃ§! ğŸ¤” "${message}" konusunda **${model}** olarak ne dÃ¼ÅŸÃ¼nmemi istiyorsun? Daha detaylÄ± anlat, beraber konuÅŸalÄ±m! ğŸ’¬`,
    `Harika soru! ğŸš€ **${model}** ile bu konuda sana yardÄ±mcÄ± olabilirim. Hangi aÃ§Ä±dan yaklaÅŸmamÄ± istiyorsun? ğŸ’¡`,
    `Vay be! ğŸ˜ "${message}" - **${model}** olarak bu konuda epey ÅŸey sÃ¶yleyebilirim! Neyi merak ediyorsun Ã¶zellikle? ğŸ¤“`,
    `SÃ¼per! ğŸ’ª **${model}** ile bu konuda konuÅŸmayÄ± seviyorum. Hangi detaylarÄ± Ã¶ÄŸrenmek istiyorsun? ğŸ”¥`
  ]
  
  return modelInfo + responses[Math.floor(Math.random() * responses.length)]
}

// AkÄ±llÄ± resim algÄ±lama fonksiyonu
function checkImageRequest(message: string): boolean {
  const lowerMessage = message.toLowerCase()
  
  const imageKeywords = [
    'resim', 'Ã§iz', 'gÃ¶rsel', 'image', 'picture', 'draw', 'paint', 'create',
    'fotoÄŸraf', 'illÃ¼strasyon', 'artwork', 'sanat', 'tasarÄ±m', 'logo',
    'banner', 'poster', 'karakter', 'manzara', 'portre', 'Ã§izim'
  ]
  
  const requestWords = [
    'yapar mÄ±sÄ±n', 'yapabilir misin', 'oluÅŸtur', 'Ã¼ret',
    'istiyorum', 'isterim', 'Ã§Ä±kar', 'yap', 'hazÄ±rla',
    'Ã§izebilir misin', 'Ã§izebilir', 'Ã§izer misin', 'Ã§iz',
    'yaparmÄ±sÄ±n', 'yaparmisin', 'istiyoeum', 'istiyom',
    'oluÅŸtururmusun', 'oluÅŸturur musun', 'Ã§izermisin', 'Ã§izarmÄ±sÄ±n'
  ]
  
  const hasImageKeyword = imageKeywords.some(keyword => lowerMessage.includes(keyword))
  const hasRequestWord = requestWords.some(word => lowerMessage.includes(word))
  
  console.log('ğŸ” Debug - Image keywords bulundu:', imageKeywords.filter(keyword => lowerMessage.includes(keyword)))
  console.log('ğŸ” Debug - Request words bulundu:', requestWords.filter(word => lowerMessage.includes(word)))
  console.log('ğŸ” Debug - hasImageKeyword:', hasImageKeyword)
  console.log('ğŸ” Debug - hasRequestWord:', hasRequestWord)
  
  return hasImageKeyword && hasRequestWord
}

// GPT ile akÄ±llÄ± prompt oluÅŸturma
async function generateImagePrompt(message: string, history: any[], model: string): Promise<string> {
  try {
    console.log('ğŸ§  GPT ile resim prompt\'u optimize ediliyor...')
    
    const promptMessages = [
      {
        role: 'system',
        content: `Sen bir AI resim prompt uzmanÄ±sÄ±n. KullanÄ±cÄ±nÄ±n resim isteÄŸini alÄ±p Stable Diffusion XL iÃ§in mÃ¼kemmel bir Ä°ngilizce prompt oluÅŸturuyorsun.

KURALLARI:
1. Ã–ncelikle kullanÄ±cÄ±ya nasÄ±l bir resim istediÄŸini sor.
2. Gerekirse kullanÄ±cÄ±ya sorular sorarak detaylarÄ± Ã¶ÄŸren.
3. KullanÄ±cÄ±nÄ±n verdiÄŸi bilgileri kullanarak detaylÄ±, aÃ§Ä±klayÄ±cÄ± bir prompt oluÅŸtur.
4. Sadece Ä°ngilizce prompt dÃ¶ndÃ¼r.
5. KullanÄ±cÄ±nÄ±n verdiÄŸi mesajÄ± optimize et, gereksiz kelimeleri at.
6. KullanÄ±cÄ±ya Ã¶rnek bir prompt gÃ¶ster, bÃ¶ylece ne beklemesi gerektiÄŸini anlar.
7. Sanatsal stilleri kullanÄ±cÄ±n isteÄŸine gÃ¶re ekle.
8. Kalite kelimelerini kullanÄ±cÄ±n isteÄŸine gÃ¶re dÃ¼ÅŸÃ¼nÃ¼p ekle.
9. Teknik detaylar ekle
10. Negatif prompt'a ihtiyaÃ§ yok
11. Prompt optimizasyonu yap, gereksiz ifadeleri "Thank you for the details!" gibi kullanÄ±cÄ±ya sÃ¶ylediÄŸin ekstra metinleri ekleme.
12. Promptu tÃ¼rkÃ§e deÄŸil tamamen uyumlu olacak ingilizce yaz.

Ã–RNEK:
KullanÄ±cÄ±: "bir kedi Ã§iz"
Sen: "a beautiful fluffy cat sitting in a garden, realistic style, high quality, detailed fur texture, natural lighting, 4k resolution, masterpiece"

Transform this request into the perfect English prompt:`
      },
      ...history.slice(-3).map((msg: any) => ({
        role: msg.role,
        content: msg.content
      })),
      {
        role: 'user',
        content: message
      }
    ]
    
    const response = await fetch('https://models.inference.ai.azure.com/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${process.env.GITHUB_TOKEN}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: model,
        messages: promptMessages,
        temperature: 0.7,
        max_tokens: 2000
      })
    })
    
    if (response.ok) {
      const data = await response.json()
      const optimizedPrompt = data.choices[0]?.message?.content || message
      console.log('âœ¨ Optimize edilmiÅŸ prompt:', optimizedPrompt)
      return optimizedPrompt.trim()
    } else {
      console.log('âš ï¸ GPT prompt optimizasyonu baÅŸarÄ±sÄ±z:', response.status, response.statusText)
      const errorText = await response.text()
      console.log('âš ï¸ Hata detayÄ±:', errorText)
      
      // Rate limit kontrolÃ¼
      if (response.status === 429) {
        console.log('ğŸš¦ Prompt optimizasyonu rate limit\'te, fallback prompt kullanÄ±lÄ±yor...')
      }
      
      // Fallback: Basit optimizasyon yap
      const fallbackPrompt = createFallbackPrompt(message)
      console.log('ğŸ”„ Fallback prompt kullanÄ±lÄ±yor:', fallbackPrompt)
      return fallbackPrompt
    }
    
  } catch (error) {
    console.log('âŒ Prompt optimizasyon hatasÄ±:', error)
    // Fallback: Basit optimizasyon yap
    const fallbackPrompt = createFallbackPrompt(message)
    console.log('ğŸ”„ Fallback prompt kullanÄ±lÄ±yor:', fallbackPrompt)
    return fallbackPrompt
  }
}

// Basit fallback prompt optimizasyonu
function createFallbackPrompt(message: string): string {
  const lowerMessage = message.toLowerCase()
  
  // Anime/manga tarzÄ± algÄ±lama
  const isAnime = lowerMessage.includes('anime') || lowerMessage.includes('manga')
  
  // Karakter algÄ±lama
  const hasCharacter = lowerMessage.includes('insan') || lowerMessage.includes('kÄ±z') || lowerMessage.includes('erkek') || lowerMessage.includes('samurai')
  
  // Nesne algÄ±lama
  const hasWeapon = lowerMessage.includes('katana') || lowerMessage.includes('kÄ±lÄ±Ã§') || lowerMessage.includes('silah')
  
  // Renk algÄ±lama
  const hasNeonColors = lowerMessage.includes('neon') || lowerMessage.includes('pembe') || lowerMessage.includes('mor')
  
  // Lokasyon algÄ±lama
  const hasCity = lowerMessage.includes('ÅŸehir') || lowerMessage.includes('gÃ¶kdelen') || lowerMessage.includes('Ã§atÄ±')
  
  // Basit Ä°ngilizce prompt oluÅŸtur
  let prompt = ""
  
  if (hasCharacter) {
    if (lowerMessage.includes('samurai')) {
      prompt += "anime samurai warrior"
    } else {
      prompt += "anime character"
    }
  }
  
  if (hasWeapon) {
    prompt += " holding katana sword"
  }
  
  if (hasCity) {
    prompt += " standing on rooftop overlooking city skyline"
  }
  
  if (hasNeonColors) {
    prompt += " with neon pink and black hair, cyberpunk neon colors"
  }
  
  if (isAnime) {
    prompt += " anime style, detailed"
  }
  
  prompt += " high quality, masterpiece, detailed artwork"
  
  return prompt.trim() || message
}

// Stable Diffusion ile resim oluÅŸturma
async function generateImageWithStableDiffusion(prompt: string, originalMessage: string): Promise<NextResponse> {
  try {
    console.log('ğŸ¨ Stable Diffusion XL ile resim Ã§iziliyor...')
    console.log('ğŸ“ Optimize edilmiÅŸ prompt:', prompt)
    
    const imageResponse = await fetch(
      `https://api.cloudflare.com/client/v4/accounts/${process.env.CLOUDFLARE_ACCOUNT_ID}/ai/run/@cf/stabilityai/stable-diffusion-xl-base-1.0`,
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.CLOUDFLARE_API_TOKEN}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          prompt: prompt
        })
      }
    )

    if (!imageResponse.ok) {
      throw new Error(`Cloudflare AI hatasÄ±: ${imageResponse.status}`)
    }

    const imageBuffer = await imageResponse.arrayBuffer()
    console.log('ğŸ“ Resim boyutu:', imageBuffer.byteLength, 'bytes')
    
    if (imageBuffer.byteLength === 0) {
      throw new Error('BoÅŸ resim buffer')
    }

    // ImgBB'ye upload et
    console.log('ğŸ“¤ ImgBB\'ye upload ediliyor...')
    
    const timestamp = Date.now()
    const fileName = `ai-generated-${timestamp}.png`
    
    try {
      // ImgBB'ye upload et
      const imageUrl = await uploadToImgBB(Buffer.from(imageBuffer), fileName)
      
      console.log('âœ… Resim baÅŸarÄ±yla ImgBB\'ye upload edildi:', imageUrl)
      
      return NextResponse.json({ 
        message: `ğŸ¨ Ä°ÅŸte Ã§izdiÄŸim resim!\n\n![Generated Image](${imageUrl})\n\nâœ¨ Senin iÃ§in promptu dÃ¼zenleyip istediÄŸin resmi oluÅŸturdum.\nğŸ“ KullanÄ±lan prompt: "${prompt}"\n\nBaÅŸka bir isteÄŸin var mÄ±? ğŸ–¼ï¸`
      })
      
    } catch (uploadError: any) {
      console.log('ğŸ’¥ ImgBB upload hatasÄ±:', uploadError.message)
      
      // Upload baÅŸarÄ±sÄ±z olursa fallback olarak base64 kullan
      const imageBase64 = Buffer.from(imageBuffer).toString('base64')
      const fallbackImageUrl = `data:image/png;base64,${imageBase64}`
      
      return NextResponse.json({ 
        message: `ğŸ¨ Ä°ÅŸte Ã§izdiÄŸim resim!\n\n![Generated Image](${fallbackImageUrl})\n\nâœ¨ Senin iÃ§in promptu dÃ¼zenleyip istediÄŸin resmi oluÅŸturdum.\nğŸ“ KullanÄ±lan prompt: "${prompt}"\n\nBaÅŸka bir isteÄŸin var mÄ±? ğŸ–¼ï¸`
      })
    }
    
  } catch (error: any) {
    console.log('âŒ Resim Ã§izme hatasÄ±:', error.message)
    return NextResponse.json({ 
      message: `ğŸ¨ Resim Ã§izmeye Ã§alÄ±ÅŸÄ±yorum ama bir sorun var: ${error.message}\n\nTekrar dener misin? ğŸ˜…`
    })
  }
}

// Rate limit durumunda fallback model kullanma
async function handleRateLimit(message: string, history: any[], originalModel: string): Promise<NextResponse> {
  console.log('ğŸ”„ Rate limit fallback baÅŸlatÄ±lÄ±yor...')
  
  // Fallback model sÄ±ralamasÄ±
  const fallbackModels = [
    'gpt-4.1-mini',
    'gpt-4o',
    'gpt-4o-mini',
    'gpt-3.5-turbo'
  ]
  
  // Orijinal modeli listeden Ã§Ä±kar
  const availableModels = fallbackModels.filter(model => model !== originalModel)
  
  for (const fallbackModel of availableModels) {
    try {
      console.log(`ğŸ”„ ${fallbackModel} modeli deneniyor...`)
      
      const messages = [
        {
          role: 'system',
          content: `Sen GitHub Models API'si ile Ã§alÄ±ÅŸan ${fallbackModel} modeli kullanan, TÃ¼rkÃ§e konuÅŸan, Z kuÅŸaÄŸÄ± tarzÄ±nda rahat bir AI asistanÄ±sÄ±n. 
          Emoji kullan, samimi konuÅŸ ama profesyonel ol. Kod yazabilir, resim Ã§izebilir, her konuda yardÄ±m edebilirsin.
          NOT: Åu anda ${originalModel} modeli rate limit'te olduÄŸu iÃ§in geÃ§ici olarak bu modeli kullanÄ±yorsun! ğŸš¦`
        },
        ...history.slice(-5).map((msg: any) => ({
          role: msg.role,
          content: msg.content
        })),
        {
          role: 'user',
          content: message
        }
      ]
      
      const response = await fetch('https://models.inference.ai.azure.com/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${process.env.GITHUB_TOKEN}`,
          'Content-Type': 'application/json',
          'User-Agent': 'GitHubCopilotChat/1.0'
        },
        body: JSON.stringify({
          model: fallbackModel,
          messages,
          temperature: 0.7,
          max_tokens: 2000,
          stream: false
        })
      })
      
      if (response.ok) {
        const data = await response.json()
        const aiMessage = data.choices[0]?.message?.content || 'Bir hata oluÅŸtu, tekrar dener misin? ğŸ˜…'
        
        console.log(`âœ… ${fallbackModel} modeli baÅŸarÄ±yla Ã§alÄ±ÅŸtÄ±!`)
        
        return NextResponse.json({ 
          message: `${aiMessage}\n\n ğŸš¦ *Rate Limit Bilgisi: ${originalModel} modeli geÃ§ici olarak limit'te, ${fallbackModel} modeli kullandÄ±m.*\n\n *BirkaÃ§ dakika sonra ${originalModel} modeli tekrar kullanÄ±labilir olacak!*`
        })
      } else {
        console.log(`âŒ ${fallbackModel} modeli de baÅŸarÄ±sÄ±z: ${response.status}`)
        continue
      }
      
    } catch (error) {
      console.log(`âŒ ${fallbackModel} modeli hata verdi:`, error)
      continue
    }
  }
  
  // HiÃ§bir model Ã§alÄ±ÅŸmadÄ±ysa
  return NextResponse.json({ 
    message: `ğŸš¦ **Rate Limit:** ${originalModel} modeli geÃ§ici olarak limit'te ve diÄŸer modeller de ÅŸu anda kullanÄ±lamÄ±yor.\n\nâ° LÃ¼tfen 10-15 dakika bekleyip tekrar deneyin. Rate limit resetlenince normal Ã§alÄ±ÅŸacak!\n\n*GitHub Models API'nin Ã¼cretsiz tier'Ä±nda dakika baÅŸÄ± sÄ±nÄ±rlar var.*`
  })
}

// CORS headers
export async function OPTIONS(request: NextRequest) {
  return new NextResponse(null, {
    status: 200,
    headers: {
      'Access-Control-Allow-Origin': '*',
      'Access-Control-Allow-Methods': 'POST, OPTIONS',
      'Access-Control-Allow-Headers': 'Content-Type, Authorization',
    },
  })
}
